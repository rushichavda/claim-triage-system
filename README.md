# ğŸ¥ Claim Triage & Resolution Agentic System

**Production-grade multi-agent system for healthcare claim denial triage and automated appeal generation**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-stateful-green.svg)](https://github.com/langchain-ai/langgraph)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“‹ Overview

**ğŸ¯ Status: ALL ASSIGNMENT DELIVERABLES COMPLETE**

This system implements a **production-grade multi-agent orchestration workflow** that:
- âœ… Ingests claim denial PDFs with byte-level offset tracking
- âœ… Extracts structured data with confidence scoring
- âœ… Retrieves relevant policies using **OpenAI text-embedding-3-small** (1536-dim embeddings)
- âœ… Reasons over policies to decide: **Appeal | NoAppeal | Escalate**
- âœ… Generates appeals with **verifiable citations** (hallucination prevention)
- âœ… Provides human-in-the-loop review interface
- âœ… Executes with guarded permissions and full audit trail

**Assignment Deliverables:**
- âœ… **System Dossier** (2 pages) - Complete architecture, agent taxonomy, threat model
- âœ… **Monitoring & Postmortem Playbook** (1 page) - KPIs, alerts, incident runbooks
- âœ… **Model Card & Documentation** (1 page) - Capabilities, limitations, ethical considerations
- âœ… **Business Case & 90-Day Rollout Plan** (1 page) - ROI model, KPI improvements, milestones
- âœ… **Prototype Repo** - Runnable Docker stack with 6 specialized agents
- âœ… **20+ Test Cases** - 10 synthetic + 10 adversarial with gold labels
- âœ… **CI/CD Harness** - Regression suite with hallucination gating
- âœ… **Zero-Hallucination Enforcement** - <2% rate via Citation Verifier

### ğŸ¯ Key Features

- **Zero-Hallucination Tolerance**: Every claim must link to verifiable source (doc ID + byte offsets)
- **HIPAA-Ready**: Encryption-at-rest, tokenized PHI in logs, redaction mechanics
- **Production-Grade**: Stateful agents, CI/CD gating, adversarial robustness testing
- **Observable**: Full audit trail, LangSmith tracing, Prometheus metrics

---

## ğŸ—ï¸ Architecture

### Multi-Agent System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ingest Service â”‚ â”€â”€â”€ PDF Parser (byte-level offsets)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Extractor Agent â”‚ â”€â”€â”€ LLM + Instructor (structured output)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Retriever Agent â”‚ â”€â”€â”€ OpenAI Embeddings + ChromaDB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Policy Reasoner     â”‚ â”€â”€â”€ LLM-based reasoning
â”‚ (Appeal/NoAppeal/   â”‚
â”‚  Escalate)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Appeal Drafter      â”‚ â”€â”€â”€ Generates appeals with citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Citation Verifier   â”‚ â”€â”€â”€ Semantic similarity check
â”‚ (Hallucination Det.)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Human Review UI     â”‚ â”€â”€â”€ Streamlit (Approve/Reject/Modify)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execution Adapter   â”‚ â”€â”€â”€ Writeback with permissions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Component | Technology |
|-----------|------------|
| **Orchestration** | LangGraph (stateful multi-agent workflow) |
| **LLM** | OpenAI GPT-4o (reasoning, extraction, drafting) |
| **Embeddings** | OpenAI text-embedding-3-small (1536 dimensions) |
| **Vector Store** | ChromaDB (embedded, no separate service) |
| **Database** | PostgreSQL + pgvector (ACID audit logs) |
| **Caching** | Redis (state management, rate limiting) |
| **API** | FastAPI (async, type-safe) |
| **UI** | Streamlit (human review interface) |
| **Observability** | LangSmith + Prometheus + Grafana |
| **Security** | Fernet encryption, Presidio (PHI redaction) |

---

## ğŸš€ Quick Start

Choose your setup based on your needs:
- **Development Mode** - Lightweight, no Docker, for testing and development
- **Production Mode** - Full stack with Docker, monitoring, and all services

---

### ğŸ“¦ Development Mode (Recommended for Testing)

Perfect for: Local development, testing, debugging

**What's included:** Core agents, ChromaDB (embedded), no Docker needed

#### Step 1: Prerequisites

```bash
# Required
- Python 3.11+
- OpenAI API key
```

#### Step 2: Setup Environment

```bash
# Clone and navigate to directory
cd claim-triage-system

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install -e .

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

#### Step 3: Generate Test Data

```bash
# Set your API key
export OPENAI_API_KEY="sk-proj-your-key-here"

# Generate 25 test files (5 policies + 20 test cases)
python scripts/generate_data_simple.py
```

**Output:** `data/policy_docs/` and `data/test_cases/` populated with test files

#### Step 4: Index Policies

```bash
# Index policy documents into ChromaDB (embedded mode)
python scripts/index_policies_openai.py
```

**Output:** ChromaDB vector store created at `data/vector_store/`

#### Step 5: Run Tests

```bash
# Run unit tests
pytest tests/unit/ -v

# Run regression suite (validates all 20 test cases)
python scripts/run_regression_suite.py
```

**Expected:** Hallucination rate <2%, Evidence coverage >85%

#### Step 6: Test Single Claim

```bash
# Process a single claim denial
python scripts/test_single_claim.py
```

**That's it!** You now have a working development environment.

**What you DON'T need in dev mode:**
- âŒ Docker / Docker Compose
- âŒ PostgreSQL database
- âŒ Redis cache
- âŒ Streamlit UI
- âŒ Prometheus / Grafana monitoring

---

### ğŸ³ Production Mode (Full Stack)

Perfect for: Production deployment, demos, full feature testing

**What's included:** All services, monitoring, UI, databases

#### Step 1: Prerequisites

```bash
# Required
- Python 3.11+
- Docker & Docker Compose
- OpenAI API key
- 8GB RAM minimum (16GB recommended)
```

#### Step 2: Setup Environment

```bash
# Clone and navigate to directory
cd claim-triage-system

# Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

#### Step 3: Generate Test Data

```bash
# Set your API key
export OPENAI_API_KEY="sk-proj-your-key-here"

# Generate test data
python scripts/generate_data_simple.py
```

#### Step 4: Index Policies

```bash
# Create virtual environment (for indexing script)
python -m venv .venv
source .venv/bin/activate
pip install -e .

# Index policies
python scripts/index_policies_openai.py
```

#### Step 5: Start Docker Stack

```bash
# Start all services
docker-compose up -d

# Check services are running
docker-compose ps

# View logs
docker-compose logs -f app
```

**Services started:**
- âœ… FastAPI (port 8000) - REST API
- âœ… PostgreSQL (port 5432) - Database
- âœ… ChromaDB (port 8001) - Vector store
- âœ… Redis (port 6379) - Cache
- âœ… Streamlit (port 8501) - UI
- âœ… Prometheus (port 9090) - Metrics
- âœ… Grafana (port 3000) - Dashboards

#### Step 6: Access Services

- **API Documentation**: http://localhost:8000/docs
- **Human Review UI**: http://localhost:8501
- **Metrics Dashboard**: http://localhost:3000 (login: admin/admin)
- **Prometheus**: http://localhost:9090

#### Step 7: Run Demo

```bash
# Process sample claims through full workflow
./run_demo.sh --docker
```

**That's it!** Full production stack is running.

---

### ğŸ§ª Quick Validation

After setup, verify everything works:

```bash
# Health check
curl http://localhost:8000/health

# Process a test claim
curl -X POST http://localhost:8000/api/v1/claims/process \
  -F "file=@data/test_cases/synthetic/denial_001_duplicate.pdf"

# Check metrics
curl http://localhost:9090/metrics | grep hallucination_rate
```

---

## ğŸ“š Additional Resources

- **System Architecture**: [`docs/SYSTEM_DOSSIER.md`](docs/SYSTEM_DOSSIER.md)
- **Citation System Deep-Dive**: [`docs/CITATION_DEEP_DIVE.md`](docs/CITATION_DEEP_DIVE.md)
- **Monitoring & Alerts**: [`docs/MONITORING_PLAYBOOK.md`](docs/MONITORING_PLAYBOOK.md)
- **Model Card**: [`docs/MODEL_CARD.md`](docs/MODEL_CARD.md)
- **Business Case**: [`docs/BUSINESS_CASE.md`](docs/BUSINESS_CASE.md)
- **Embedding Usage**: [`docs/EMBEDDING_USAGE.md`](docs/EMBEDDING_USAGE.md)

---

## ğŸ§ª Testing

### Test Structure

```
tests/
â”œâ”€â”€ unit/              # Unit tests for individual agents
â”œâ”€â”€ integration/       # Integration tests (multi-agent flows)
â”œâ”€â”€ adversarial/       # Red-team adversarial test cases
â””â”€â”€ regression/        # Regression harness (20 testcases)
```

### Run Tests

```bash
# All tests
make test

# Unit tests only
make test-unit

# Integration tests
make test-integration

# Adversarial tests
make test-adversarial
```

### CI Gating

```yaml
# CI policy: Block merge if:
- hallucination_rate > 2%
- evidence_coverage < 85%
- test_pass_rate < 100%
```

---

## ğŸ“Š Data Schemas

### Core Models

- **Claim & ClaimDenial**: Structured claim data with PHI fields (encrypted)
- **Citation & CitationSpan**: Byte-level source tracking
- **AuditEvent & AuditLog**: Immutable audit trail
- **Decision & DecisionRationale**: Policy reasoning output
- **Appeal & AppealDraft**: Generated appeals with citations

### Example: Citation with Byte Offsets

```json
{
  "citation_id": "cit-123",
  "claim_text": "Policy Section 4.2.1 states...",
  "source_span": {
    "document_id": "doc-456",
    "start_byte": 1234,
    "end_byte": 1450,
    "extracted_text": "Emergency services exception...",
    "page_number": 3,
    "extraction_confidence": 0.95
  },
  "verified": true,
  "verification_score": 0.92
}
```

---

## ğŸ” Security & Compliance

### HIPAA Controls

- âœ… **Encryption-at-Rest**: Fernet (AES-256) for PHI fields
- âœ… **Tokenized Logging**: PHI replaced with deterministic tokens
- âœ… **Redaction**: Presidio-based PII/PHI detection
- âœ… **Least Privilege**: Guarded execution permissions (READ_ONLY | WRITE_APPEALS | ADMIN)
- âœ… **Audit Trail**: Immutable append-only logs with full lineage

### Threat Model

| Risk | Severity | Mitigation | Detection |
|------|----------|------------|-----------|
| Hallucination | **CRITICAL** | Citation verification, semantic similarity | Audit events, CI gating |
| PHI Leak | **CRITICAL** | Encryption, tokenization, redaction | Structured logging, alerts |
| Prompt Injection | HIGH | Input validation, sandboxing | Adversarial tests |
| Data Poisoning | HIGH | Document hash verification | Content integrity checks |

---

## ğŸ“ˆ Monitoring & Observability

### Key Metrics (Prometheus)

```python
# Hallucination rate (CRITICAL)
hallucination_rate = failed_citations / total_citations

# Evidence coverage
evidence_coverage = verified_citations / total_claims

# False accept rate
false_accept_rate = incorrect_approvals / total_decisions

# Cost per case
cost_per_case = total_tokens * token_cost
```

### Alerts

- ğŸš¨ **Hallucination rate > 2%**: Block deployments, escalate to humans
- âš ï¸ **Evidence coverage < 85%**: Review appeal quality
- âš ï¸ **Avg latency > 30s**: Scale infrastructure

---

## ğŸ› ï¸ Development

### Project Structure

```
claim-triage-system/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ agents/           # All agent implementations
â”‚   â”‚   â”œâ”€â”€ extractor/
â”‚   â”‚   â”œâ”€â”€ retriever/
â”‚   â”‚   â”œâ”€â”€ policy_reasoner/
â”‚   â”‚   â”œâ”€â”€ citation_verifier/
â”‚   â”‚   â”œâ”€â”€ appeal_drafter/
â”‚   â”‚   â””â”€â”€ executor/
â”‚   â”œâ”€â”€ ingest/           # PDF parsing
â”‚   â”œâ”€â”€ orchestrator/     # LangGraph workflow
â”‚   â”œâ”€â”€ human_review/     # Streamlit UI
â”‚   â””â”€â”€ shared/           # Schemas, utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ policy_docs/      # Policy document store
â”‚   â”œâ”€â”€ test_cases/       # 20 test cases (10 synthetic + 10 adversarial)
â”‚   â””â”€â”€ vector_store/     # ChromaDB persistence
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

### Add a New Agent

1. Create directory: `services/agents/your_agent/`
2. Implement: `your_agent_agent.py` with clear API contract
3. Add to workflow: Update `services/orchestrator/workflow.py`
4. Write tests: `tests/unit/test_your_agent.py`
5. Update docs

---

## ğŸ“– Documentation

### Core Documentation (Assignment Deliverables)

1. **System Dossier** (2 pages): [`docs/SYSTEM_DOSSIER.md`](docs/SYSTEM_DOSSIER.md)
   - Complete architecture diagrams and service maps
   - Agent taxonomy with detailed specifications
   - Data contracts and schemas
   - Threat model & risk management framework
   - HIPAA compliance controls

2. **Monitoring & Postmortem Playbook** (1 page): [`docs/MONITORING_PLAYBOOK.md`](docs/MONITORING_PLAYBOOK.md)
   - Key metrics (KPIs) and alert thresholds
   - Canary deployment & rollback procedures
   - Incident runbook for hallucination events
   - Grafana dashboard configuration

3. **Model Card & Documentation** (1 page): [`docs/MODEL_CARD.md`](docs/MODEL_CARD.md)
   - Training/prompt provenance
   - Model capabilities and limitations
   - Recommended usage and required human checks
   - Ethical considerations and bias mitigation

4. **Business Case & 90-Day Rollout Plan** (1 page): [`docs/BUSINESS_CASE.md`](docs/BUSINESS_CASE.md)
   - Expected ROI model (638% 3-year ROI)
   - Measurable KPI improvements
   - Detailed 90-day rollout milestones
   - Risk mitigation and staffing changes

### Additional Documentation

- **Setup Comparison**: [`SETUP_COMPARISON.md`](SETUP_COMPARISON.md) - Development vs Production mode comparison
- **Project Completion Summary**: [`PROJECT_COMPLETION_SUMMARY.md`](PROJECT_COMPLETION_SUMMARY.md)
- **Implementation Status**: [`docs/IMPLEMENTATION_STATUS.md`](docs/IMPLEMENTATION_STATUS.md)
- **Model Configuration**: [`docs/MODEL_CONFIGURATION.md`](docs/MODEL_CONFIGURATION.md)
- **Running Guide**: [`docs/RUNNING_GUIDE.md`](docs/RUNNING_GUIDE.md)

---

## ğŸ¤ Contributing

```bash
# Setup pre-commit hooks
pre-commit install

# Run full CI pipeline locally
make all

# Format code before commit
make format
```

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE)

---

## ğŸ™ Acknowledgments

- **LangGraph**: Stateful multi-agent orchestration
- **OpenAI**: GPT-4o for reasoning and text-embedding-3-small for embeddings

---

## ğŸ“ Support

- **Issues**: https://github.com/your-org/claim-triage-system/issues
- **Docs**: https://docs.your-org.com/claim-triage

---

**Built with â¤ï¸ for healthcare compliance automation**
